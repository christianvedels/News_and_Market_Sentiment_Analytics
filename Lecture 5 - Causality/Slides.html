<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>News and Market Sentiment Analytics</title>
    <meta charset="utf-8" />
    <meta name="author" content="Christian Vedel,  Department of Economics   Email: christian-vs@sam.sdu.dk" />
    <script src="libs/header-attrs-2.28/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link href="libs/panelset-0.3.0/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.3.0/panelset.js"></script>
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <script src="libs/xaringanExtra-progressBar-0.0.1/progress-bar.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# News and Market Sentiment Analytics
]
.subtitle[
## Lecture 5: Causality
]
.author[
### Christian Vedel,<br> Department of Economics<br><br> Email: <a href="mailto:christian-vs@sam.sdu.dk" class="email">christian-vs@sam.sdu.dk</a>
]
.date[
### Updated 2025-12-05
]

---






<style>.xe__progress-bar__container {
  top:0;
  opacity: 1;
  position:absolute;
  right:0;
  left: 0;
}
.xe__progress-bar {
  height: 0.25em;
  background-color: #808080;
  width: calc(var(--slide-current) / var(--slide-total) * 100%);
}
.remark-visible .xe__progress-bar {
  animation: xe__progress-bar__wipe 200ms forwards;
  animation-timing-function: cubic-bezier(.86,0,.07,1);
}
@keyframes xe__progress-bar__wipe {
  0% { width: calc(var(--slide-previous) / var(--slide-total) * 100%); }
  100% { width: calc(var(--slide-current) / var(--slide-total) * 100%); }
}</style>







&lt;style type="text/css"&gt;
.pull-left {
  float: left;
  width: 44%;
}
.pull-right {
  float: right;
  width: 44%;
}
.pull-right ~ p {
  clear: both;
}


.pull-left-wide {
  float: left;
  width: 66%;
}
.pull-right-wide {
  float: right;
  width: 66%;
}
.pull-right-wide ~ p {
  clear: both;
}

.pull-left-narrow {
  float: left;
  width: 30%;
}
.pull-right-narrow {
  float: right;
  width: 30%;
}

.small123 {
  font-size: 0.80em;
}

.large123 {
  font-size: 2em;
}

.red {
  color: red
}
&lt;/style&gt;

# Last time

.pull-left[
- Tokenization and embedding spaces  
- *Coding challenge:* zero-shot sentiment classifier with embeddings
]

.pull-right-narrow[

![Trees](Figures/Trees.jpg)

]

---

# Today's lecture

.pull-left[
- Why **causality** in news &amp; markets?  
- Directed Acyclic Graphs (DAGs)  
- **d-separation** and conditional independence  
- Time series: AR and MA models  
- **Granger causality**  
- Coding challenge: data-driven causal analysis
]

???

- You can say: “Today we’ll mostly stay on intuition + a few key equations.”
- Next: three concrete news shocks to motivate why causality matters.

---

class: middle
# Three recent news shocks

.pull-left[
1. Trump’s **“Liberation Day”** tariff announcement  
2. The **DeepSeek** AI “Sputnik moment”  
3. Sam Altman’s **AI bubble** comments

Each looks like *news → market reaction*.

Question we’ll keep asking:

&gt; What is *actually* causing what in these pictures?

]

.pull-right-narrow[
.small123[
We’ll look at three small scripts:

- `Code/liberation_day.py`  
- `Code/deepseek.py`  
- `Code/technews_and_AI_stocks.py`
]
]

???

- Briefly say when each happened and what the headlines were.
- Tell them: “All three plots you’re about to see are generated by those Python scripts in the repo.”

---

class: middle
# 1. Trump's "Liberation Day"

.pull-left[
- New tariff announcement (“Liberation Day”)  
- Broad US indices around the date

- Code: `Code/liberation_day.py`
]

.pull-right[
![Liberation Day reaction](Code/liberation_day_market_reaction.png)
]

???

- Ask: "If I only show you this picture, what story do you tell?"
- Likely answer: tariffs → future growth fears → indices drift down.
- Flag that we don’t yet know if it’s *tariffs directly* or global conditions, Fed expectations, etc.

---

class: middle
# 2. DeepSeek "Sputnik moment"

.pull-left[
- Chinese AI startup releases ultra-cheap model  
- NVDA loses record \$590B in one day  

- Code: `Code/deepseek.py`
]

.pull-right[
![DeepSeek reaction](Code/deepseek_ai_shock_reaction.png)
]

???

- Point to NVDA (thick line) vs others.
- Ask: “Does this plot prove DeepSeek *caused* the drop? What else might be going on?”
- Mention we’ll later think about common shocks, expectations, and feedback.

---

class: middle
# 3. Sam Altman on the AI bubble

.pull-left[
- Sam Altman publicly worries about an **AI bubble**  
- Magnificent 7 (AI-heavy tech) around that date

- Code: `Code/technews_and_AI_stocks.py`
]

.pull-right[
![AI bubble quote reaction](Code/ai_bubble_quote_reaction.png)
]

???

- Highlight that here prices don’t obviously crash on the quote.
- Useful contrast: strong narrative, weaker *visual* reaction.
- Sets up the idea that news and prices can move together, but causality isn’t obvious.

---

class: middle
# From pictures to causal questions

.pull-left-wide[
In all three cases we informally say:

&gt; “News moved the market.”

But many rival stories fit the same plots:

- News `\(\to\)` prices  
- Prices `\(\to\)` news  
- Macro / liquidity `\(\to\)` both

Today we’ll:

- Use **DAGs** and **d-separation** to formalise these stories  
- Use **AR/MA** models and **Granger tests** to ask:

  `$$\text{Do past headlines help predict returns?}$$`
]


???

- Tie back explicitly to the three examples:
  - “Liberation Day tariffs”, “DeepSeek shock”, “Altman bubble quote”.
- Say you’ll revisit them when talking about DAGs and Granger causality.

---

class: middle
# Toy example: Ice cream and drowning

.pull-left[
- Classic summer data set:

  - `\(X_t\)`: ice cream sales  
  - `\(Y_t\)`: drowning accidents

- In the toy data:
  - As `\(X_t\)` goes up, `\(Y_t\)` tends to go up

- Question:

  &gt; Does buying ice cream **cause** drowning?
  
]

.pull-right[

.panelset[
.panel[.panel-name[Plot 1]
![Drowning in icecreams](Figures/Icecream_drownings.png)
]

.panel[.panel-name[Plot 2]
![Drowning in months](Figures/Drownings_month.png)
]

]


]

---
# Simple regression results


``` r
library(fixest)
data = read.csv("Code/Icecream_kills.csv")
mod1 = feols(drownings ~ icecream, data=data)
mod2 = feols(drownings ~ icecream | month, data=data)
etable(mod1, mod2)
```

```
##                               mod1            mod2
## Dependent Var.:          drownings       drownings
##                                                   
## Constant        0.9622*** (0.0340)                
## icecream        0.0847*** (0.0040) 0.0015 (0.0043)
## Fixed-Effects:  ------------------ ---------------
## month                           No             Yes
## _______________ __________________ _______________
## S.E. type                      IID       by: month
## Observations                 1,000           1,000
## R2                         0.31504         0.66796
## Within R2                       --         0.00015
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```



---
class: middle, inverse

# Causality: Why care?

- If you get good enough you can do **Causal Inference**
- With the introduction: You can do a sniff test on stories:
  + "Does it make sense that X causes Y?"
  + "Could there be something else going on?"
  
---
class: middle
# Causal hierarchy (Pearl’s ladder) 
### *Importantly: You cannot move up the ladder without assumptions*

.pull-left-wide[
.pull-left-narrow[
![Assumptions](Figures/Assumptions.png)
]

.pull-right-wide[
1. **Association**  
   - `\(P(Y \mid X)\)`  
   - "What tends to go together?"

2. **Intervention**  
   - `\(P(Y \mid \text{do}(X))\)`  
   - "What happens if we **force** `\(X\)`?"

3. **Counterfactuals**  
   - `\(P(Y_x \mid X', Y')\)`  
   - "What **would have** happened if ...?"
]


]

--

.pull-right-narrow[
Our regression gives:

  `$$P(Y \mid X)$$`

But we *want*:

  `$$P(Y \mid \text{do}(X))$$`

In words:

  &gt; If we forced ice cream sales up,  
  &gt; would drownings go up?
  
]

???
- Stress: statistics alone gives you level 1 by default.
- Causal inference is about moving from `\(P(Y\mid X)\)` to `\(P(Y\mid \text{do}(X))\)` using assumptions and structure.
  
---
class: middle
# Enter DAGs

.pull-left-wide[
- A **Directed Acyclic Graph (DAG)**:

  - Nodes = variables  
  - Arrows = causal influence

- For ice cream:

  - `\(M \rightarrow X\)`  
  - `\(M \rightarrow Y\)`  
  - No arrow `\(X \rightarrow Y\)`
  
  
- *Lacking arrows encode our assumptions*
]

.pull-right-narrow[
![Ice cream DAG](Figures/DAG.png)
]

???
- Say explicitly: “This is our *story* about the world, not something the data automatically know.”
- Highlight that **missing** arrows are strong assumptions too.
- Point out that `\(M\)` is a confounder: common cause of both `\(X\)` and `\(Y\)`.


---
class: middle
# Canonical structures

.pull-left[
1. **Chain** (mediator)  

   `$$X \rightarrow Z \rightarrow Y$$`

2. **Fork** (common cause)  

   `$$X \leftarrow Z \rightarrow Y$$`

3. **Collider** (common effect)  

   `$$X \rightarrow Z \leftarrow Y$$`
]

.pull-right-narrow[
- Ice cream example:

  `$$X \leftarrow M \rightarrow Y$$`

- This is a **fork**:

  - `\(M\)` causes both `\(X\)` and `\(Y\)`  
  - Confounding if `\(M\)` is ignored
]

???
- Quickly sketch the three patterns on the board.
- Ask: "Which one fits ice cream &amp; drowning?" --&gt; the fork.

---
class: middle
# Central trick

&gt; *Under some conditions we can estimate `\(P(Y \mid \text{do}(X))\)` from observational quantities.*

.pull-left-wide[

- Idea: **block the backdoor paths** from `\(X\)` to `\(Y\)`

- Find a set of variables `\(Z\)` such that:
  - `\(Z\)` d-separates `\(X\)` and `\(Y\)` when we ignore arrows  
    **out of** `\(X\)` (no open backdoor paths)

- Then we can identify:

  `$$P(Y \mid \text{do}(X)) = \sum_z P(Y \mid X, Z=z)\,P(Z=z)$$`

- Ice cream example:
  - `\(Z = \{M\}\)` (month)
  - Controlling for `\(M\)` removes the spurious  
    `\(X \leftarrow M \rightarrow Y\)` path
]

???

- Call this (informally) the **backdoor criterion**.
- Link back to the fixed-effects regression:
  - With month FE, the ice-cream coefficient moves toward the *causal* effect (≈0 here).
- Flag that in the news &amp; markets setting, our main challenge is choosing a sensible `\(Z\)`.

---
class: middle
# d-separation (graphical independence)

.pull-left[
Let `\(X\)`, `\(Y\)` and `\(Z\)` be (sets of) nodes in a DAG.

We say **$X$ and `\(Y\)` are d-separated by `\(Z\)`**  
if **every path** between any node in `\(X\)` and any node in `\(Y\)` is **blocked** when we condition on `\(Z\)`.

A path is **blocked** if it contains at least one node that blocks it, using these rules:
]

.pull-right-narrow[
- **Chain / fork**  

  `$$X \rightarrow M \rightarrow Y, \quad
    X \leftarrow M \rightarrow Y$$  

  Path is blocked if we **condition on `\(M\)`**.

- **Collider**  

  `$$X \rightarrow M \leftarrow Y$$`  

  Path is blocked if we do **not** condition on `\(M\)`  
  or any descendant of `\(M\)`.  
  Conditioning on a collider **opens** the path.
]

???

- Emphasise: d-separation is a purely **graphical** criterion.
- If the DAG is correct, d-separation corresponds to (conditional) **independence** in the data.
- This is what lets us use the graph to choose adjustment sets for causal effects.


---
class: middle
# Takeaways (so far)

.pull-left-wide[
1. **Causal structures are assumptions**

   - The DAG is your **story** about the world  
   - Data can support or contradict it indirectly,  
     but you can’t “prove” the arrows from correlations alone  
   - (Speculation: some causal structure might **emerge** in very large ML systems, but we’re not there yet in this course)

2. **DAGs are thinking tools**

   - Force you to say what you believe causes what  
   - Let you spot **confounders**, **colliders**, and bad controls  
   - With d-separation, you can find sensible adjustment sets to turn some `\(P(Y \mid X, Z)\)` into `\(P(Y \mid do(X))\)`
]

.pull-right-narrow[
3. **Where to read more**

   - Judea Pearl (2009): *Causality* (technical)
   - Judea Pearl, Madelyn Glymour, Nicholas P. Jewell (2016): *Causal Inference in Statistics: A Primer* (intro)
   - Judea Pearl (2018): *The Book of Why* (popular science)
   - Scott Cunningham (2021): *The Mixtape* (applied econ focus)

.small123[
Same core ideas you’ve seen today:  
DAGs, d-separation, and the gap between `\(P(Y\mid X)\)` and `\(P(Y\mid do(X))\)`.
]
]

???

- Stress point 1: the graph is never “estimated” by OLS here; it’s a structured way to write down assumptions.
- Point 2: connect back to ice cream + drownings and the three market news stories.
- Point 3: say which book is closest to this course (probably Mixtape + What If for their style).


---
class: middle
# Exercise 1: Confounder (fork)

.pull-left[
**Story**

- `\(X\)`: Ice cream sales  
- `\(Y\)`: Drowning accidents  
- `\(M\)`: Month

`\(M\)` affects both `\(X\)` and `\(Y\)`.

**Tasks**

1. Draw a DAG for `\((X, Y, T)\)`  
2. Decide if `\(X\)` and `\(Y\)` are d-separated:

   - (a) Given **nothing**  
   - (b) Given `\(M\)`
]



???
- Expected DAG: `\(X \leftarrow M \rightarrow Y\)` (fork).
- Answer:  
  - (a) Not d-separated → associated.  
  - (b) d-separated by `\(M\)` → `\(X \perp Y \mid M\)`.
  
  
---
class: middle
# Exercise 2: Mediator (chain)

.pull-left[
**Story**

- `\(X\)`: New surprisingly good numbers on inflation
- `\(M\)`: Investor optimism  
- `\(Y\)`: Stock index return  

You believe:

- News changes optimism
- Optimism moves the index

**Tasks**

1. Draw a DAG for `\((X, M, Y)\)`  
2. Decide if `\(X\)` and `\(Y\)` are d-separated:

   - (a) Given **nothing**  
   - (b) Given `\(M\)`
]

.pull-right-narrow[
**Questions**

- Do `\(X\)` and `\(Y\)` remain associated  
  when we **control for** `\(M\)`?

- In practice: if you regress `\(Y\)` on `\(X\)` and `\(M\)`,  
  what are you doing to the `\(X \rightarrow M \rightarrow Y\)` path?
]

???
- Expected DAG: `\(X \rightarrow M \rightarrow Y\)` (chain).
- Answer:  
  - (a) Not d-separated → `\(X\)` and `\(Y\)` associated.  
  - (b) d-separated by `\(M\)` → `\(X \perp Y \mid M\)`.
- Good moment to mention that conditioning on a mediator “blocks” total effect and leaves direct effect (if any).

---
class: middle
# Exercise 3: Collider

.pull-left-wide[

- `\(X\)`: true product quality  
- `\(Y\)`: marketing spend  
- `\(Z\)`: "featured on TechNews front page"

Editors feature firms that are:

- very high quality **or**  
- very heavy on marketing


]

.pull-right-narrow[
**Questions**

- Does more marketing spending *cause* better/worse products?
]

???

So both `\(X\)` and `\(Y\)` increase `\(P(Z=1)\)`:

`$$X \rightarrow Z \leftarrow Y$$`

**What happens if we condition on `\(Z=1\)`?**

- In the full population:  
  `\(X\)` and `\(Y\)` are (roughly) independent

- Among featured firms (`\(Z=1\)`):

  - High `\(X\)` firms don't need big `\(Y\)`  
  - High `\(Y\)` firms can get by with low `\(X\)`

- We see a **negative correlation** and might conclude:

&gt; "Among featured firms, more marketing means worse products."

This is a spurious conclusion from  
**conditioning on a collider**.

- On the board:  
  1. Draw a round cloud for `\((X,Y)\)` (no correlation).  
  2. Draw a diagonal threshold, keep only points above it (`\(Z=1\)`).  
  3. Show that the remaining points line up with a negative slope.
- Emphasise: this is about **selection**; many empirical datasets are implicitly "Z=1 only".


---
class: middle
# From DAGs to time series

.pull-left[
- So far:
  - Static DAGs  
  - Ice cream vs drownings  
  - News vs returns as **cross-sectional snapshots**

- Next step:
  - Markets and news are **time series**  
  - Yesterday’s values matter for today
]

--

.pull-right-narrow[
### Goal

  &gt; Add **time** to our causal thinking and see how to test "X helps predict Y"

- Yet again, only an introduction

]

???

- Transition line: "Now let’s add the `\(t\)`-index back in and think about sequences, not just one-day plots."


---
class: middle
# AR and MA models: what they do

.pull-left[
**Autoregressive (AR)**

- `\(Y_t\)` depends on its **own past**

  `$$Y_t = \phi_1 Y_{t-1} + \dots + \phi_p Y_{t-p} + \varepsilon_t$$`

- Captures **momentum / mean reversion**

**Moving average (MA)**

- `\(Y_t\)` depends on **past shocks**

  `$$Y_t = \mu + \varepsilon_t + \theta_1 \varepsilon_{t-1} + \dots$$`

- Captures **short-lived shock effects**
]

.pull-right-narrow[
We’ll:

- Show a simple AR(1) and MA(1) in code  
- Fit them to a returns series  
- Use them as a **baseline** before we add news/sentiment
]

???

- Emphasise: “These are just glorified linear regressions on lags.”
- Mention that you’ll keep it at AR(1)/MA(1) for intuition, not full ARIMA theory.


---
class: middle
# Granger causality: idea

.pull-left[
Question:

&gt; Does series `\(X_t\)` help predict `\(Y_t\)`  
&gt; **beyond** what past `\(Y\)` already tells us?

Definition (informal):

- `\(X\)` **Granger-causes** `\(Y\)` if  
  including past `\(X\)` improves forecasts of `\(Y\)`.

We’ll:

- Compare models with and without lagged `\(X\)`  
- Use `statsmodels`’ Granger test
]

.pull-right-narrow[
Links to earlier part:

- DAG story: “news `\(\to\)` returns” vs “returns `\(\to\)` news”
- Granger story:
  - Does past news predict returns?  
  - Does past returns predict news?

- Granger `\(\neq\)` full causal proof,  
  but it’s a **useful diagnostic** in time series.
]

???

- Flag explicitly: “This is a *forecast-based* notion of causality.”
- Good time to remind them: “Cause must come before effect in time.”


---
class: middle
# A returns series for AR/MA

.pull-left[
- We need a **time series** `\(R_t\)`  

- Example:

  - Daily close for SPY (S&amp;P 500 ETF)  
  - Compute daily log returns

- This will be our toy `\(Y_t\)` for AR/MA:
  - `\(Y_t = R_t\)`
]



???

- Emphasise that any other asset/index would work.
- Mention that we use **returns**, not raw prices, to be closer to stationarity.

---
class: middle
# AR(1) in practice

.pull-left[
We estimate:

`$$R_t = \phi_1 R_{t-1} + \varepsilon_t$$`

- Use `statsmodels` ARIMA with `order=(1,0,0)`  
- No trend term (focus on the autoregressive part)

Interpretation of `\(\hat\phi_1\)`:

- `\(\hat\phi_1 \approx 0\)`: little persistence  
- `\(\hat\phi_1 &gt; 0\)`: momentum  
- `\(\hat\phi_1 &lt; 0\)`: mean reversion
]


???

- Ask: “Do daily SPY returns show strong AR(1) structure?”
- Point out that for many liquid assets, `\(\hat\phi_1\)` is small.


---
class: middle
# MA(1) in practice

.pull-left[
Now we estimate:

`$$R_t = \mu + \varepsilon_t + \theta_1 \varepsilon_{t-1}$$`

- Use `statsmodels` ARIMA with `order=(0,0,1)`  
- `\(\theta_1\)` captures how **yesterday’s shock** spills into today

Interpretation:

- `\(|\hat\theta_1|\)` small: shocks die quickly  
- Larger `\(|\hat\theta_1|\)`: stronger short-run structure in returns
]

???

- Compare AR(1) vs MA(1) estimates.
- You can ask: “Which one seems to capture more structure in this series?”

---
class: middle
# AR(1) vs MA(1): fitted vs actual

.pull-left[
- Plot:

  - Actual returns `\(R_t\)`  
  - AR(1) fitted values `\(\hat R^{\text{AR}}_t\)`  
  - MA(1) fitted values `\(\hat R^{\text{MA}}_t\)`

- Just for a short window (e.g. 200 days)

- The point is **intuition**, not perfect fit.
]


???

- Emphasise that returns are noisy; we don’t expect a perfect visual fit.
- The goal is to show that AR/MA capture *some* temporal structure.

---
class: middle
# Granger causality with news and returns

.pull-left[
We now have two time series:

- `\(H_t\)`: **news sentiment** index  
  (e.g. daily average sentiment from headlines)

- `\(R_t\)`: **stock return**  
  (e.g. daily log return on an ETF or index)

Question:

&gt; Does past sentiment `\(H_{t-1}, H_{t-2}, \dots\)`  
&gt; help predict `\(R_t\)` once we already use past `\(R\)`?

]

.pull-right-narrow[
- This is a **Granger causality** question:

  - “Does `\(H\)` add forecasting power for `\(R\)`  
    beyond lagged `\(R\)` itself?”

- In practice we will:

  - Build `\(H_t\)` from news (earlier lectures)  
  - Build `\(R_t\)` from prices  
  - Compare models with and without lagged `\(H\)`
]

???

- Remind them: `\(H_t\)` can be any reasonable summary of news (mean sentiment, share of negative headlines, etc.).
- Emphasise that the focus is on **predictive content** of `\(H\)` for `\(R\)`.

---
class: middle
# What Granger can (and cannot) tell us

.pull-left[
**What it can tell us**

- Does past `\(H\)` improve forecasts of `\(R\)`?  
- Does past `\(R\)` improve forecasts of `\(H\)`?  
- For which lags `\(p\)` is the effect strongest?

Useful for:

- Designing **forecasting models**  
- Understanding **lead–lag** patterns
]

.pull-right-narrow[
**What it cannot (by itself) tell us**

- The full structural **DAG** behind `\(H\)` and `\(R\)`  
- Whether a third process `\(M_t\)` drives both  
- What happens under a true **intervention**  
  (e.g. “no negative AI news today”)

For that we still need:

- DAG thinking (confounders, colliders, etc.)  
- Domain knowledge and controls  
- Sometimes natural experiments or instruments
]

???

- Tie back to Pearl’s ladder:
  - Granger lives mostly at "association with a time arrow".
- Good closing line:
  - “Granger tells us *who moves first* in a predictive sense;  
    causal DAGs help us think about *why*.”



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
  "highlightStyle": "github",
  "highlightLines": true,
  "countIncrementalSlides": false,
  "ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url(SDU_logo.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 1em;
  right: 1em;
  width: 125px;
  height: 60px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // insert more to hide here
    ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
